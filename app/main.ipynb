{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Import the required libraries and files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fasttext\n",
    "from scipy.stats import uniform\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Local Packages\n",
    "import hats.config\n",
    "import hats.utility as ut\n",
    "from hats.data_preprocessing import Preprocessing\n",
    "import hats.ml_model as ml\n",
    "from hats.config import CONFIG\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_data = pd.read_csv('../dataset/dataset.csv', sep=';')\n",
    "translate_data = pd.read_csv('../dataset/translations_data.csv', sep=';')\n",
    "sms_translations_data = pd.read_csv('../dataset/sms_translations.csv', sep=';')\n",
    "\n",
    "stop_words = []\n",
    "with open('../dataset/stop_words.txt') as f:\n",
    "  stop_words = f.readlines()\n",
    "  stop_words = [word.replace('\\n', '') for word in stop_words]"
   ]
  },
  {
   "source": [
    "# Fasttext Model Training "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_proprocess: Preprocessing = Preprocessing(stop_words, sms_translations_data)\n",
    "home_data_preprocessed = data_proprocess.preprocessing(home_data.copy())\n",
    "data_proprocess.saveToCsv(home_data_preprocessed)\n",
    "\n",
    "# Process the output file to remove double quotes (\"\")\n",
    "!sed -i 's/\"//g' ../output/comm_preprocessed.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a fasttext model in supervised fashion\n",
    "ft_model = ml.createFasttextModel(CONFIG.OUTPUT_DATASET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.9943791627883911, 'batti'),\n",
       " (0.9886794090270996, 'balab'),\n",
       " (0.974006175994873, 'lights'),\n",
       " (0.9539253115653992, 'balb'),\n",
       " (0.9465795755386353, 'blb'),\n",
       " (0.9458802938461304, 'btti'),\n",
       " (0.9401957988739014, 'bulb'),\n",
       " (0.7651400566101074, 'jla'),\n",
       " (0.6618971824645996, 'dark'),\n",
       " (0.650171160697937, '</s>')]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Testing the fasttext model\n",
    "ft_model.get_nearest_neighbors('light')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(('__label__geyser_off',), array([0.99944645]))"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "ft_model.predict('mai chahta hu ki tum geyser band kr do')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "ft_model.get_sentence_vector('mai chahta hu ki tum geyser band kr do').shape"
   ]
  },
  {
   "source": [
    "# Create additional columns to preprocessed dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Create <i><b>sent_vec</b></i> column in main dataset for sentence vectors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       commands               label  \\\n",
       "0   batti bujha  __label__light_off   \n",
       "1   balab bujha  __label__light_off   \n",
       "2    balab band  __label__light_off   \n",
       "3    light band  __label__light_off   \n",
       "4   light bujha  __label__light_off   \n",
       "5     light off  __label__light_off   \n",
       "6          dark  __label__light_off   \n",
       "7     off light  __label__light_off   \n",
       "8     off light  __label__light_off   \n",
       "9  batti bujhaw  __label__light_off   \n",
       "\n",
       "                                            sent_vec  \n",
       "0  [0.09129511, -0.17886868, 0.013367534, -0.0127...  \n",
       "1  [0.043475877, -0.17572588, -0.015810117, -0.02...  \n",
       "2  [0.06676102, -0.18724361, 0.15825129, 0.110632...  \n",
       "3  [0.080121726, -0.20910013, 0.120552175, 0.0859...  \n",
       "4  [0.056836586, -0.19758242, -0.053509228, -0.04...  \n",
       "5  [0.070388824, -0.18570364, 0.093462825, 0.0803...  \n",
       "6  [0.11362806, -0.17577863, -0.0051939115, -0.04...  \n",
       "7  [0.070388824, -0.18570364, 0.093462825, 0.0803...  \n",
       "8  [0.070388824, -0.18570364, 0.093462825, 0.0803...  \n",
       "9  [0.08482814, -0.13813066, -0.010202765, -0.037...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>commands</th>\n      <th>label</th>\n      <th>sent_vec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>batti bujha</td>\n      <td>__label__light_off</td>\n      <td>[0.09129511, -0.17886868, 0.013367534, -0.0127...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>balab bujha</td>\n      <td>__label__light_off</td>\n      <td>[0.043475877, -0.17572588, -0.015810117, -0.02...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>balab band</td>\n      <td>__label__light_off</td>\n      <td>[0.06676102, -0.18724361, 0.15825129, 0.110632...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>light band</td>\n      <td>__label__light_off</td>\n      <td>[0.080121726, -0.20910013, 0.120552175, 0.0859...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>light bujha</td>\n      <td>__label__light_off</td>\n      <td>[0.056836586, -0.19758242, -0.053509228, -0.04...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>light off</td>\n      <td>__label__light_off</td>\n      <td>[0.070388824, -0.18570364, 0.093462825, 0.0803...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>dark</td>\n      <td>__label__light_off</td>\n      <td>[0.11362806, -0.17577863, -0.0051939115, -0.04...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>off light</td>\n      <td>__label__light_off</td>\n      <td>[0.070388824, -0.18570364, 0.093462825, 0.0803...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>off light</td>\n      <td>__label__light_off</td>\n      <td>[0.070388824, -0.18570364, 0.093462825, 0.0803...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>batti bujhaw</td>\n      <td>__label__light_off</td>\n      <td>[0.08482814, -0.13813066, -0.010202765, -0.037...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "home_data_vectorized = data_proprocess.convertCommandToVector(home_data_preprocessed, ft_model)\n",
    "home_data_vectorized.head(10)"
   ]
  },
  {
   "source": [
    "## 2. Add a column for each class using OVR scheme\n",
    "\n",
    "After adding the columns, create a single layer perceptron model with 150 inputs and 1 output with sigmoid activation. \n",
    "\n",
    "Total number of such models will be equal to the number of classes in the dataset. This is to train multiple models using the OVR technique and while predicting, we will use all the models to predict the final class label of the test command."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_data_ovr = ut.add_class_ovr_cols(home_data_vectorized.copy())"
   ]
  },
  {
   "source": [
    "# Tensorflow Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ml.createPerceptronModels(home_data_ovr['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m_name in models.keys():\n",
    "    models[m_name].compile(optimizer=keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.6937 - accuracy: 0.4948 - val_loss: 0.6781 - val_accuracy: 0.5625\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 0.6852 - accuracy: 0.5104 - val_loss: 0.6695 - val_accuracy: 0.6042\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.6776 - accuracy: 0.5521 - val_loss: 0.6616 - val_accuracy: 0.6042\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.6706 - accuracy: 0.5990 - val_loss: 0.6540 - val_accuracy: 0.6250\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.6638 - accuracy: 0.6042 - val_loss: 0.6470 - val_accuracy: 0.5833\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 0.6575 - accuracy: 0.6042 - val_loss: 0.6404 - val_accuracy: 0.6042\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.6511 - accuracy: 0.6354 - val_loss: 0.6345 - val_accuracy: 0.6458\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.6450 - accuracy: 0.6302 - val_loss: 0.6286 - val_accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.6397 - accuracy: 0.6719 - val_loss: 0.6237 - val_accuracy: 0.7083\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.6340 - accuracy: 0.6927 - val_loss: 0.6181 - val_accuracy: 0.7083\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.6285 - accuracy: 0.6927 - val_loss: 0.6128 - val_accuracy: 0.7292\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.6236 - accuracy: 0.6927 - val_loss: 0.6069 - val_accuracy: 0.7500\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.6184 - accuracy: 0.7188 - val_loss: 0.6018 - val_accuracy: 0.7708\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.6134 - accuracy: 0.7292 - val_loss: 0.5967 - val_accuracy: 0.7708\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.6083 - accuracy: 0.7396 - val_loss: 0.5919 - val_accuracy: 0.7708\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.6037 - accuracy: 0.7500 - val_loss: 0.5871 - val_accuracy: 0.7917\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 0.5991 - accuracy: 0.7552 - val_loss: 0.5819 - val_accuracy: 0.7917\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.5941 - accuracy: 0.7656 - val_loss: 0.5772 - val_accuracy: 0.7917\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 0.5898 - accuracy: 0.7865 - val_loss: 0.5727 - val_accuracy: 0.8125\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.5854 - accuracy: 0.7865 - val_loss: 0.5677 - val_accuracy: 0.8125\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 0.5810 - accuracy: 0.8021 - val_loss: 0.5640 - val_accuracy: 0.8125\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.5767 - accuracy: 0.8281 - val_loss: 0.5594 - val_accuracy: 0.8125\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.5722 - accuracy: 0.8490 - val_loss: 0.5551 - val_accuracy: 0.8125\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.5681 - accuracy: 0.8542 - val_loss: 0.5507 - val_accuracy: 0.8333\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.5641 - accuracy: 0.8594 - val_loss: 0.5464 - val_accuracy: 0.8542\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 42ms/step - loss: 0.5602 - accuracy: 0.8698 - val_loss: 0.5419 - val_accuracy: 0.9167\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.5559 - accuracy: 0.8698 - val_loss: 0.5377 - val_accuracy: 0.9167\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.5519 - accuracy: 0.8698 - val_loss: 0.5340 - val_accuracy: 0.9167\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.5480 - accuracy: 0.8698 - val_loss: 0.5301 - val_accuracy: 0.9167\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.5446 - accuracy: 0.8698 - val_loss: 0.5263 - val_accuracy: 0.9167\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.5405 - accuracy: 0.8698 - val_loss: 0.5219 - val_accuracy: 0.9167\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.5366 - accuracy: 0.8698 - val_loss: 0.5178 - val_accuracy: 0.9167\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.5333 - accuracy: 0.8698 - val_loss: 0.5139 - val_accuracy: 0.9167\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.5296 - accuracy: 0.8698 - val_loss: 0.5102 - val_accuracy: 0.9167\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.5260 - accuracy: 0.8854 - val_loss: 0.5063 - val_accuracy: 0.9167\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5225 - accuracy: 0.8802 - val_loss: 0.5023 - val_accuracy: 0.9167\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.5194 - accuracy: 0.8958 - val_loss: 0.4989 - val_accuracy: 0.9375\n",
      "Epoch 38/50\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5148 - accuracy: 0.9000"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cee79d756ccb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome_data_ovr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Model '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'plot_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arjun/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arjun/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    870\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    873\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arjun/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arjun/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arjun/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arjun/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/home/arjun/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arjun/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arjun/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arjun/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/home/arjun/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for X_train, X_test, y_train, y_test, label in ut.data_split_classwise(home_data_ovr):\n",
    "    history = models[label].fit(X_train, y_train, batch_size=20, epochs=50, validation_data=(X_test, y_test))\n",
    "    ut.plot(history.history, 'Model ' + label, 'plot_' + label + '.png')\n",
    "    break"
   ]
  },
  {
   "source": [
    "# Scikit-learn models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Grid search using SVC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ut.data_split(home_data_ovr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(C = [10e-5, 10e-4, 10e-3, 10e-2, 10e-1, 1, 10e1, 10e2, 10e4],\\\n",
    "    kernel=['linear', 'rbf', 'poly'])\n",
    "svc_model = SVC(probability=True, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator=svc_model, param_grid=parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "pickle.dump(clf, open('../' + CONFIG.OUTPUT_DIRECTORY_NAME + CONFIG.SVM_MODEL_SAVEFILE, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear', probability=True, random_state=40)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.01886121 0.00526422 0.05359809 0.00883506 0.80203765 0.0244259\n  0.03267593 0.007419   0.03890349 0.00797945]]\n['__label__geyser_off']\n"
     ]
    }
   ],
   "source": [
    "test_data = np.reshape(ft_model.get_sentence_vector('mai chahta hu ki tum geyser band kr do'), (1, -1))\n",
    "print(clf.predict_proba(test_data))\n",
    "print(clf.predict(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['__label__ac_off', '__label__ac_on', '__label__fan_off',\n",
       "       '__label__fan_on', '__label__geyser_off', '__label__geyser_on',\n",
       "       '__label__light_off', '__label__light_on', '__label__tv_off',\n",
       "       '__label__tv_on'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'__label__geyser_off'"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "clf.classes_[np.argmax(clf.predict_proba(test_data)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Other'"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "filename = '../' + CONFIG.OUTPUT_DATASET_FILE + CONFIG.SVM_MODEL_SAVEFILE\n",
    "ml.predict('tu pahal hai bhai geyser', ft_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}